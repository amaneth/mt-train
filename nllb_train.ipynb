{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ee8304-9d7d-40f5-855d-cd39a1bfbb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/miniconda3/envs/tiny/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/aman/miniconda3/envs/tiny/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0380471-3ed3-4c76-96bd-1c807e559fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                                            model_name,\n",
    "                                            device_map='auto',\n",
    "                                            use_cache=False\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88babd1-d4c0-4fc2-a9a5-f63cf9c74a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf54fd4-c9d1-447a-8a78-c873151ec64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(\"amaniopia/merged_train\", split=\"train\")\n",
    "valid_ds = load_dataset(\"amaniopia/flores-merged\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b833901-2f85-40e7-a45d-98b57ef83f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['source', 'target', 'src_lang', 'tgt_lang'],\n",
       "     num_rows: 3145570\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['source', 'target', 'src_lang', 'tgt_lang'],\n",
       "     num_rows: 29910\n",
       " }))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89df35ad-dfd9-43b9-8005-de13603a3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = train_ds.filter(lambda example : example[\"src_lang\"] in [\"eng_Latn\", \"amh_Ethi\", \"swh_Latn\"] and example[\"tgt_lang\"] in [\"eng_Latn\", \"amh_Ethi\", \"swh_Latn\"])\n",
    "small_train = small_train.shuffle(seed=42).select(range(0,4000))\n",
    "small_valid = valid_ds.filter(lambda example : example[\"src_lang\"] in [\"eng_Latn\", \"amh_Ethi\", \"swh_Latn\"] and example[\"tgt_lang\"] in [\"eng_Latn\", \"amh_Ethi\", \"swh_Latn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2e84f9-4067-4d2b-8f21-00b12e371a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['source', 'target', 'src_lang', 'tgt_lang'],\n",
       "     num_rows: 4000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['source', 'target', 'src_lang', 'tgt_lang'],\n",
       "     num_rows: 3988\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train, small_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228f06cc-1550-4a8f-8a7d-6dab309caac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    inputs = examples[\"source\"]\n",
    "    targets = examples[\"target\"]\n",
    "    src_langs = examples[\"src_lang\"]\n",
    "    tgt_langs = examples[\"tgt_lang\"]\n",
    "\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "\n",
    "    for src, tgt, src_lang, tgt_lang in zip(inputs, targets, src_langs, tgt_langs):\n",
    "        tokenizer.src_lang = src_lang\n",
    "        tokenizer.tgt_lang = tgt_lang\n",
    "\n",
    "\n",
    "        tokenized = tokenizer(\n",
    "            src,\n",
    "            text_target=tgt,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        input_ids.append(tokenized[\"input_ids\"])\n",
    "        labels.append(tokenized[\"labels\"])\n",
    "\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5cdba1-9293-44d5-868f-95134b0f7234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:02<00:00, 1747.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize datasets\n",
    "tokenized_train = small_train.map(tokenize_fn, batched=True, remove_columns=train_ds.column_names)\n",
    "tokenized_valid = small_valid.map(tokenize_fn, batched=True, remove_columns=valid_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b048131a-3c02-45b3-a236-701bfe081d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amh_Ethi', 'eng_Latn', 'swh_Latn'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(small_valid[\"tgt_lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc4aff7-8521-4542-bac2-7eac0c53dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amh_Ethi ሰኞ እለት፣ በስታንፎርድ ዩኒቨርሲቲ የህክምና ትምህርት ቤት ህዋሶችን በአይነት የሚያስቀምጥ አዲስ የምርመራ መሳሪያ እንደተፈጠረ አስታውቋል፡ እያንዳንዱን በአንደ የዩ.ኤስ ሳንቲም የሚሆን መደበኛ የኢንክጄት አታሚዎችን በመጠቀም ሊፈበረክ የሚችል ትንሽ መታተም የሚችል ቺፕ።</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_valid[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9d7e2a-41c7-4641-ae85-596734e90395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng_Latn On Monday, scientists from the Stanford University School of Medicine announced the invention of a new diagnostic tool that can sort cells by type: a tiny printable chip that can be manufactured using standard inkjet printers for possibly about one U.S. cent each.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_valid[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c945901f-03ba-44cd-bbd4-229804539f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, logging\n",
    "from huggingface_hub import HfFolder\n",
    "import os\n",
    "\n",
    "epochs = 2\n",
    "learning_rate = 5e-5\n",
    "batch_size = 4\n",
    "\n",
    "hf_id = \"amaniopia\"  # change to your huggingface username\n",
    "output_dir = os.path.join(hf_id, f\"nllb-200-3.3B-finetuned\")\n",
    "\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_accumulation_steps=4,\n",
    "    #gradient_checkpointing=True,\n",
    "\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type='constant',  # \"constant\", \"linear\", \"cosine\"\n",
    "\n",
    "    eval_strategy=\"steps\",  # or \"epoch\"\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\", # \"tensorboard\", \"wandb\", or \"none\"\n",
    "\n",
    "    # push to hub parameters\n",
    "    push_to_hub=True,\n",
    "    hub_private_repo=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7500092f-ae65-4499-8d9d-c7e1dd062aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 21:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.427800</td>\n",
       "      <td>4.746602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.114600</td>\n",
       "      <td>1.174518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.106117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.088193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.085897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/miniconda3/envs/tiny/lib/python3.12/site-packages/transformers/modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=2.2355946826934816, metrics={'train_runtime': 1299.3975, 'train_samples_per_second': 6.157, 'train_steps_per_second': 0.385, 'total_flos': 8668418408448000.0, 'train_loss': 2.2355946826934816, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc9c800-c22c-4375-8bab-d722ae571c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "# Delete model, tokenizer, and trainer objects\n",
    "# del model\n",
    "del tokenizer\n",
    "try:\n",
    "    del trainer\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Run garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7291e853-6f86-4bfa-9624-cc963e58a2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 13 09:01:37 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   30C    P0              55W / 300W |  19078MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2756      C   ...man/miniconda3/envs/tiny/bin/python    19070MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a588103-79e2-4a37-9085-cf55dcbda7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
